{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be420c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SL.NO</th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>UHID</th>\n",
       "      <th>PRESENTATION</th>\n",
       "      <th>CLINICAL DIAGNOSIS</th>\n",
       "      <th>DOS</th>\n",
       "      <th>FNAC</th>\n",
       "      <th>Stage_2_class</th>\n",
       "      <th>HPE</th>\n",
       "      <th>Stage_3</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>CORRELATION YES/NO</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RATHI SHEDTHI</td>\n",
       "      <td>67.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1481122</td>\n",
       "      <td>SOLITARY NODULE WITH LYMPH NODES</td>\n",
       "      <td>CARCINOMA</td>\n",
       "      <td>27/3/2023</td>\n",
       "      <td>PAPILLARY CARCINOMA B-IV</td>\n",
       "      <td>4</td>\n",
       "      <td>HASHIMOTO'S THYROIDITIS</td>\n",
       "      <td>THYROIDITIS</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>TN</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SHABEENA</td>\n",
       "      <td>22.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1482969</td>\n",
       "      <td>SOLITARY NODULE - SUDDEN INCREASE IN SIZE</td>\n",
       "      <td>CARCINOMA</td>\n",
       "      <td>29/3/2024</td>\n",
       "      <td>FOLLICULAR NEOPLASM B- IV</td>\n",
       "      <td>4</td>\n",
       "      <td>MULTINODULAR GOITRE</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>TN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>VINAY K</td>\n",
       "      <td>31.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1400945</td>\n",
       "      <td>SOLITARY NODULE</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>29/3/2023</td>\n",
       "      <td>NODULAR GOITRE B-II</td>\n",
       "      <td>2</td>\n",
       "      <td>GRAVE'S DISEASE</td>\n",
       "      <td>THYROIDITIS</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>TN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>REKHA</td>\n",
       "      <td>35.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1484783</td>\n",
       "      <td>SOLITARY NODULE</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>8/4/2023</td>\n",
       "      <td>NODULAR GOITRE, B- II</td>\n",
       "      <td>2</td>\n",
       "      <td>MULTINODULAR GOITRE</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>TN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SALMA</td>\n",
       "      <td>38.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1485303</td>\n",
       "      <td>SOLITARY NODULE</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>15/4/2023</td>\n",
       "      <td>NODULAR GOITRE, B - II</td>\n",
       "      <td>2</td>\n",
       "      <td>MULTINODULAR GOITRE</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>TN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SL.NO           NAME  AGE  GENDER     UHID  \\\n",
       "0      1  RATHI SHEDTHI  67.0      F  1481122   \n",
       "1      2       SHABEENA  22.0      F  1482969   \n",
       "2      3        VINAY K  31.0      M  1400945   \n",
       "3      4          REKHA  35.0      F  1484783   \n",
       "4      5          SALMA  38.0      F  1485303   \n",
       "\n",
       "                                PRESENTATION CLINICAL DIAGNOSIS        DOS  \\\n",
       "0           SOLITARY NODULE WITH LYMPH NODES          CARCINOMA  27/3/2023   \n",
       "1  SOLITARY NODULE - SUDDEN INCREASE IN SIZE          CARCINOMA  29/3/2024   \n",
       "2                           SOLITARY NODULE              BENIGN  29/3/2023   \n",
       "3                           SOLITARY NODULE              BENIGN   8/4/2023   \n",
       "4                            SOLITARY NODULE             BENIGN  15/4/2023   \n",
       "\n",
       "                        FNAC  Stage_2_class                      HPE  \\\n",
       "0   PAPILLARY CARCINOMA B-IV              4  HASHIMOTO'S THYROIDITIS   \n",
       "1  FOLLICULAR NEOPLASM B- IV              4      MULTINODULAR GOITRE   \n",
       "2        NODULAR GOITRE B-II              2          GRAVE'S DISEASE   \n",
       "3      NODULAR GOITRE, B- II              2      MULTINODULAR GOITRE   \n",
       "4     NODULAR GOITRE, B - II              2      MULTINODULAR GOITRE   \n",
       "\n",
       "       Stage_3  Unnamed: 12 CORRELATION YES/NO Predicted   Unnamed: 15  \n",
       "0  THYROIDITIS            0                  N         TN         93.0  \n",
       "1       BENIGN            1                  N         TN          NaN  \n",
       "2  THYROIDITIS            1                  N         TN          NaN  \n",
       "3       BENIGN            1                  Y         TN          NaN  \n",
       "4       BENIGN            1                  Y         TN          NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df_all = pd.read_csv('data1.csv')\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d8b453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 5 3 1]\n",
      "['THYROIDITIS' 'BENIGN' 'CARCINOMA' 'BENIGN **' ' BENIGN']\n"
     ]
    }
   ],
   "source": [
    "print(df_all['Stage_2_class'].unique())\n",
    "print(df_all['Stage_3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c90047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['pred'] = df_all['Stage_2_class'].map({1:0, 2:0, 3:0, 4:0, 5:1})\n",
    "df_all['gt'] = df_all['Stage_3'].map({'THYROIDITIS':0, 'BENIGN':0, 'CARCINOMA':1, ' BENIGN':0, 'BENIGN **':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2803a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(df_all['gt'].unique())\n",
    "print(df_all['pred'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9405c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_confusion_matrix_df(ground_truth_col, predicted_col, data):\n",
    "  \"\"\"\n",
    "  Calculates confusion matrix and returns TP, TN, FP, FN from a DataFrame.\n",
    "\n",
    "  Args:\n",
    "      ground_truth_col (str): Name of the column containing ground truth labels.\n",
    "      predicted_col (str): Name of the column containing predicted labels.\n",
    "      data (pandas.DataFrame): The DataFrame containing ground truth and prediction columns.\n",
    "\n",
    "  Returns:\n",
    "      dict: Dictionary containing TP, TN, FP, FN values.\n",
    "  \"\"\"\n",
    "  # Ensure columns exist in DataFrame\n",
    "  if ground_truth_col not in data.columns or predicted_col not in data.columns:\n",
    "    raise ValueError(\"Ground truth and prediction columns don't exist in the DataFrame.\")\n",
    "\n",
    "  # Get ground truth and predicted labels as NumPy arrays\n",
    "  ground_truth = data[ground_truth_col].to_numpy()\n",
    "  predictions = data[predicted_col].to_numpy()\n",
    "\n",
    "  # Create the confusion matrix\n",
    "  cm = confusion_matrix(ground_truth, predictions)\n",
    "\n",
    "  # Extract values from confusion matrix\n",
    "  TP = cm[1, 1]\n",
    "  TN = cm[0, 0]\n",
    "  FP = cm[0, 1]\n",
    "  FN = cm[1, 0]\n",
    "\n",
    "  # Return results as a dictionary\n",
    "  return {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44a698d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive (TP): 10\n",
      "True Negative (TN): 90\n",
      "False Positive (FP): 3\n",
      "False Negative (FN): 3\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "#data = pd.DataFrame({'ground_truth': [0, 1, 0, 1, 0], 'prediction': [0, 0, 1, 1, 0]})\n",
    "results = calculate_confusion_matrix_df('gt', 'pred', df_all)\n",
    "\n",
    "print(f\"True Positive (TP): {results['TP']}\")\n",
    "print(f\"True Negative (TN): {results['TN']}\")\n",
    "print(f\"False Positive (FP): {results['FP']}\")\n",
    "print(f\"False Negative (FN): {results['FN']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f143279d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred   0   1\n",
       "gt          \n",
       "0     90   3\n",
       "1      3  10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_table = pd.crosstab(df_all['gt'], df_all['pred'])\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcf8ff67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared statistic: 50.926203460262535\n",
      "p-value: 9.590469137412312e-13\n",
      "1 [[81.59433962 11.40566038]\n",
      " [11.40566038  1.59433962]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2_statistic, p_value, degrees_of_freedom, expected_frequencies = chi2_contingency(contingency_table)\n",
    "print(\"Chi-squared statistic:\", chi2_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "print(degrees_of_freedom, expected_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "306bb68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 94.34%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_accuracy(ground_truth_col, predicted_col, data):\n",
    "  \"\"\"\n",
    "  Calculates overall accuracy from a DataFrame containing ground truth and predicted labels.\n",
    "\n",
    "  Args:\n",
    "      ground_truth_col (str): Name of the column containing ground truth labels.\n",
    "      predicted_col (str): Name of the column containing predicted labels.\n",
    "      data (pandas.DataFrame): The DataFrame containing ground truth and prediction columns.\n",
    "\n",
    "  Returns:\n",
    "      float: Overall accuracy as a percentage.\n",
    "  \"\"\"\n",
    "  # Ensure columns exist in DataFrame\n",
    "  if ground_truth_col not in data.columns or predicted_col not in data.columns:\n",
    "    raise ValueError(\"Ground truth and prediction columns don't exist in the DataFrame.\")\n",
    "\n",
    "  # Get ground truth and predicted labels as NumPy arrays\n",
    "  ground_truth = data[ground_truth_col].to_numpy()\n",
    "  predictions = data[predicted_col].to_numpy()\n",
    "\n",
    "  # Create confusion matrix\n",
    "  cm = confusion_matrix(ground_truth, predictions)\n",
    "\n",
    "  # Calculate total number of data points\n",
    "  total = sum(sum(row) for row in cm)\n",
    "\n",
    "  # Calculate number of correctly classified data points\n",
    "  correct = cm[0, 0] + cm[1, 1]\n",
    "\n",
    "  # Calculate overall accuracy\n",
    "  accuracy = correct / total * 100\n",
    "\n",
    "  return accuracy\n",
    "\n",
    "# Example usage\n",
    "#data = pd.DataFrame({'ground_truth': [0, 1, 0, 1, 0], 'prediction': [0, 0, 1, 1, 0]})\n",
    "data = df_all\n",
    "accuracy = calculate_accuracy('gt', 'pred', data)\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "decbb7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     88.173763\n",
      "1    630.781538\n",
      "Name: gt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_weighted_accuracy(ground_truth_col, predicted_col, data, class_weights):\n",
    "  \"\"\"\n",
    "  Calculates weighted accuracy from a DataFrame using class weights.\n",
    "\n",
    "  Args:\n",
    "      ground_truth_col (str): Name of the column containing ground truth labels.\n",
    "      predicted_col (str): Name of the column containing predicted labels.\n",
    "      data (pandas.DataFrame): The DataFrame containing ground truth and prediction columns.\n",
    "      class_weights (dict): Dictionary containing weights for each class label.\n",
    "\n",
    "  Returns:\n",
    "      float: Weighted accuracy as a percentage.\n",
    "  \"\"\"\n",
    "  # Ensure columns exist in DataFrame\n",
    "  if ground_truth_col not in data.columns or predicted_col not in data.columns:\n",
    "    raise ValueError(\"Ground truth and prediction columns don't exist in the DataFrame.\")\n",
    "\n",
    "  # Get ground truth and predicted labels as NumPy arrays\n",
    "  ground_truth = data[ground_truth_col].to_numpy()\n",
    "  predictions = data[predicted_col].to_numpy()\n",
    "\n",
    "  # Create confusion matrix\n",
    "  cm = confusion_matrix(ground_truth, predictions)\n",
    "\n",
    "  # Ensure class weights have same number of elements as unique classes\n",
    "  if len(class_weights) != len(set(ground_truth)):\n",
    "    raise ValueError(\"Number of class weights must match the number of unique classes.\")\n",
    "\n",
    "  # Calculate weighted sum of correctly classified data points\n",
    "  correct = 0\n",
    "  for i in range(len(cm)):\n",
    "    for j in range(len(cm[0])):\n",
    "      correct += cm[i, j] * class_weights.get(ground_truth[i], 1)  # Use weight 1 for unseen classes\n",
    "\n",
    "  # Calculate total number of data points (weighted by class weights)\n",
    "  total = sum(data[ground_truth_col].value_counts() * class_weights.get(val, 1) for val in data[ground_truth_col].unique())\n",
    "\n",
    "  # Calculate weighted accuracy\n",
    "  accuracy = correct / total * 100\n",
    "\n",
    "  return accuracy\n",
    "\n",
    "# Example usage (assuming class labels 0 and 1)\n",
    "#data = pd.DataFrame({'ground_truth': [0, 1, 0, 1, 0], 'prediction': [0, 0, 1, 1, 0]})\n",
    "data = df_all\n",
    "class_weights = {0: 77.36, 1: 22.64}  # Class 0 is twice as important\n",
    "\n",
    "accuracy = calculate_weighted_accuracy('gt', 'pred', data, class_weights)\n",
    "\n",
    "#print(f\"Weighted Accuracy: {accuracy:.2f}%\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "158784fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (Recall): 76.9231\n",
      "Specificity: 96.7742\n",
      "Positive Predictive Value (PPV): 76.9231\n",
      "Negative Predictive Value (NPV): 96.7742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_metrics(ground_truth_col, predicted_col, data):\n",
    "  \"\"\"\n",
    "  Calculates sensitivity, specificity, PPV, and NPV from a DataFrame.\n",
    "\n",
    "  Args:\n",
    "      ground_truth_col (str): Name of the column containing ground truth labels.\n",
    "      predicted_col (str): Name of the column containing predicted labels.\n",
    "      data (pandas.DataFrame): The DataFrame containing ground truth and prediction columns.\n",
    "\n",
    "  Returns:\n",
    "      dict: Dictionary containing sensitivity, specificity, PPV, and NPV values.\n",
    "  \"\"\"\n",
    "  # Ensure columns exist in DataFrame\n",
    "  if ground_truth_col not in data.columns or predicted_col not in data.columns:\n",
    "    raise ValueError(\"Ground truth and prediction columns don't exist in the DataFrame.\")\n",
    "\n",
    "  # Get ground truth and predicted labels as NumPy arrays\n",
    "  ground_truth = data[ground_truth_col].to_numpy()\n",
    "  predictions = data[predicted_col].to_numpy()\n",
    "\n",
    "  # Create confusion matrix\n",
    "  cm = confusion_matrix(ground_truth, predictions)\n",
    "\n",
    "  # Calculate true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN)\n",
    "  TP = cm[1, 1]\n",
    "  TN = cm[0, 0]\n",
    "  FP = cm[0, 1]\n",
    "  FN = cm[1, 0]\n",
    "\n",
    "  # Ensure no division by zero (avoid NaN)\n",
    "  if TP + FN == 0:\n",
    "    sensitivity = 0\n",
    "  else:\n",
    "    sensitivity = TP / (TP + FN)  # Recall\n",
    "\n",
    "  if TN + FP == 0:\n",
    "    specificity = 0\n",
    "  else:\n",
    "    specificity = TN / (TN + FP)\n",
    "\n",
    "  if TP + FP == 0:\n",
    "    ppv = 0\n",
    "  else:\n",
    "    ppv = TP / (TP + FP)  # Precision\n",
    "\n",
    "  if TN + FN == 0:\n",
    "    npv = 0\n",
    "  else:\n",
    "    npv = TN / (TN + FN)\n",
    "\n",
    "  # Return dictionary containing metrics\n",
    "  return {\n",
    "      \"sensitivity\": sensitivity,\n",
    "      \"specificity\": specificity,\n",
    "      \"ppv\": ppv,\n",
    "      \"npv\": npv\n",
    "  }\n",
    "\n",
    "# Example usage\n",
    "data = df_all\n",
    "metrics = calculate_metrics('gt', 'pred', data)\n",
    "\n",
    "print(f\"Sensitivity (Recall): {metrics['sensitivity']*100:.4f}\")\n",
    "print(f\"Specificity: {metrics['specificity']*100:.4f}\")\n",
    "print(f\"Positive Predictive Value (PPV): {metrics['ppv']*100:.4f}\")\n",
    "print(f\"Negative Predictive Value (NPV): {metrics['npv']*100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e7c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6f1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
